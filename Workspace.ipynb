{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddf78e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f986396c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(838, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.74477384e-01, -1.63831685e-01, -1.35869209e-01,\n",
       "        -3.43874127e+00,  2.37755480e+01, -4.00866363e+01],\n",
       "       [ 1.67067050e-01, -1.67639249e-01, -1.50782968e-01,\n",
       "        -5.11945810e+00,  2.62284567e+01, -3.92865724e+01],\n",
       "       [ 1.72185677e-01, -1.69576100e-01, -1.48127622e-01,\n",
       "        -5.29403237e+00,  2.60699932e+01, -4.01751540e+01],\n",
       "       ...,\n",
       "       [ 2.02502671e-02,  1.24621935e-01, -5.38594353e-02,\n",
       "        -1.73131726e+00,  5.37846570e+00,  1.13835737e+01],\n",
       "       [ 2.43196351e-02,  1.48991006e-01, -5.70397839e-02,\n",
       "        -1.70376107e+00,  5.34112077e+00,  1.53030257e+01],\n",
       "       [ 2.62054949e-02,  1.42276164e-01, -5.33861444e-02,\n",
       "        -2.31000922e+00,  5.23995696e+00,  1.49240854e+01]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks_rt = np.load(\"demo/00181_aligned_rt.npy\")\n",
    "print(landmarks_rt.shape)\n",
    "landmarks_rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff11c307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(838, 68, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 71.65449107, 105.97002259, -58.03470724],\n",
       "        [ 74.14772765, 122.49500343, -57.93752665],\n",
       "        [ 77.78608195, 135.72322465, -58.12510086],\n",
       "        ...,\n",
       "        [130.86798778, 154.05465987,  31.62941615],\n",
       "        [125.29169835, 154.66378422,  32.0362845 ],\n",
       "        [122.16683297, 155.06906687,  31.92402122]],\n",
       "\n",
       "       [[ 72.29225688, 104.91738109, -56.79290427],\n",
       "        [ 75.12423307, 122.14263469, -56.51504764],\n",
       "        [ 77.30651153, 134.77508331, -56.98304275],\n",
       "        ...,\n",
       "        [131.78641774, 153.83821056,  30.70624466],\n",
       "        [126.1933492 , 154.51482319,  31.24115416],\n",
       "        [122.33352098, 155.11386138,  30.8845388 ]],\n",
       "\n",
       "       [[ 73.02702758, 106.36417218, -57.70124326],\n",
       "        [ 74.00476878, 121.58658443, -58.17543856],\n",
       "        [ 78.03596307, 136.30661331, -58.16969863],\n",
       "        ...,\n",
       "        [131.93041094, 154.8424242 ,  31.41045394],\n",
       "        [126.35158949, 155.51581872,  31.83988219],\n",
       "        [120.61611178, 154.03418035,  31.01805626]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 72.23595783, 109.21169971, -58.99552681],\n",
       "        [ 74.55921761, 123.19852   , -58.97311992],\n",
       "        [ 76.89883798, 137.18222689, -58.81949103],\n",
       "        ...,\n",
       "        [133.73671475, 152.18428797,  28.57331278],\n",
       "        [126.6749088 , 152.56907707,  28.80467622],\n",
       "        [122.49927794, 152.83088146,  26.90876442]],\n",
       "\n",
       "       [[ 72.57551077, 109.12477981, -59.74552485],\n",
       "        [ 73.39710164, 123.19029778, -59.4921044 ],\n",
       "        [ 75.84909537, 137.9436462 , -59.19755302],\n",
       "        ...,\n",
       "        [133.6363366 , 152.38763203,  29.37854504],\n",
       "        [128.1338113 , 152.70668282,  29.57934722],\n",
       "        [122.36653911, 153.07675296,  28.0075029 ]],\n",
       "\n",
       "       [[ 72.6124241 , 108.55919149, -60.25221525],\n",
       "        [ 74.98149401, 122.53600597, -59.83925271],\n",
       "        [ 77.40712803, 137.29145625, -59.31424026],\n",
       "        ...,\n",
       "        [132.99233448, 151.83923214,  29.90501305],\n",
       "        [127.54808751, 153.70747465,  29.92428272],\n",
       "        [121.6521015 , 152.50897125,  27.91305348]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks_front = np.load(\"demo/00181_aligned_front.npy\")\n",
    "print(landmarks_front.shape)\n",
    "landmarks_front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b923318b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(838, 68, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 58.5163335 ,  85.9147421 , -43.72132492],\n",
       "        [ 58.5163335 , 102.35510907, -46.72382355],\n",
       "        [ 60.08208273, 115.66397757, -49.67019272],\n",
       "        ...,\n",
       "        [122.71205215, 156.37345769,  25.36199188],\n",
       "        [117.23192983, 156.37345769,  26.62683868],\n",
       "        [114.10043135, 156.37345769,  26.99474907]],\n",
       "\n",
       "       [[ 59.97498282,  84.04582134, -42.78192902],\n",
       "        [ 59.97498282, 101.26906293, -45.63965607],\n",
       "        [ 59.97498282, 113.79505681, -48.40725327],\n",
       "        ...,\n",
       "        [123.38782686, 155.28741155,  24.24307251],\n",
       "        [117.90770453, 155.28741155,  25.65537834],\n",
       "        [113.99333145, 155.28741155,  25.90433311]],\n",
       "\n",
       "       [[ 60.73904299,  85.3516753 , -43.75348663],\n",
       "        [ 59.17329375, 100.22629303, -46.78611755],\n",
       "        [ 60.73904299, 115.10091077, -49.8232193 ],\n",
       "        ...,\n",
       "        [124.15188702, 156.59326551,  24.54066467],\n",
       "        [118.6717647 , 156.59326551,  25.85572243],\n",
       "        [113.19164238, 154.24464166,  26.32324791]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 76.6242234 , 106.5412357 , -63.11425781],\n",
       "        [ 78.18997264, 120.63297882, -63.13388824],\n",
       "        [ 79.75572187, 134.72472194, -63.02124405],\n",
       "        ...,\n",
       "        [124.37957509, 154.29658739,  30.3530674 ],\n",
       "        [117.33370353, 154.29658739,  29.70008278],\n",
       "        [113.41933044, 154.29658739,  27.29662704]],\n",
       "\n",
       "       [[ 78.81455904, 106.4383198 , -66.18075562],\n",
       "        [ 78.81455904, 120.53006292, -66.20912933],\n",
       "        [ 80.38030827, 135.40468066, -65.97567749],\n",
       "        ...,\n",
       "        [123.43841225, 154.9765461 ,  29.71476555],\n",
       "        [117.95828992, 154.9765461 ,  29.09174156],\n",
       "        [112.4781676 , 154.9765461 ,  26.67568398]],\n",
       "\n",
       "       [[ 79.46325427, 105.58297171, -66.91441345],\n",
       "        [ 81.0290035 , 119.67471483, -66.58948517],\n",
       "        [ 82.59475274, 134.54933257, -66.16897583],\n",
       "        ...,\n",
       "        [124.08710748, 154.12119801,  29.5219574 ],\n",
       "        [118.60698515, 155.68694725,  28.71746063],\n",
       "        [113.12686283, 154.12119801,  25.93164062]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks = np.load(\"demo/00181_aligned.npy\")\n",
    "print(landmarks.shape)\n",
    "landmarks_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fc86608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "from collections import OrderedDict\n",
    "from PIL import Image\n",
    "import pickle as pkl\n",
    "\n",
    "from options.test_options import TestOptions\n",
    "from data.data_loader import CreateDataLoader\n",
    "from models.models import create_model\n",
    "import util.util as util\n",
    "from util.visualizer import Visualizer\n",
    "from util import html\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pdb\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "def add_audio(video_name, audio_dir):\n",
    "    command = 'ffmpeg -i ' + video_name  + ' -i ' + audio_dir + ' -vcodec copy  -acodec copy -y  ' + video_name.replace('.mp4','.mov')\n",
    "\n",
    "    print (command)\n",
    "    os.system(command)\n",
    "\n",
    "def image_to_video(sample_dir = None, video_name = None):\n",
    "    command = 'ffmpeg -framerate 25  -i ' + sample_dir +  '/%05d.jpg -c:v libx264 -y -vf \"pad=ceil(iw/2)*2:ceil(ih/2)*2\"  ' + video_name \n",
    "    print (command)\n",
    "    os.system(command)\n",
    "\n",
    "def get_param(pickle_data, pick_id, opt, lrs_package=None):\n",
    "    paths = pickle_data[pick_id]\n",
    "\n",
    "    # check shot\n",
    "    ref_nums = opt.ref_img_id.split(',')\n",
    "    if opt.n_shot % len(ref_nums) != 0:\n",
    "        print('reference number error')\n",
    "        exit(0)\n",
    "    else:\n",
    "        ref_nums = ref_nums * (opt.n_shot // len(ref_nums))\n",
    "        opt.ref_img_id = ','.join(ref_nums)\n",
    "\n",
    "    if opt.dataset_name == 'vox':\n",
    "        # target\n",
    "        opt.tgt_video_path = paths[0]+\"_aligned.mp4\"\n",
    "        if opt.no_head_motion:\n",
    "            opt.tgt_lmarks_path = paths[0]+\"_aligned_front.npy\"\n",
    "        else:\n",
    "            opt.tgt_lmarks_path = paths[0]+\"_aligned.npy\"\n",
    "        opt.tgt_rt_path = paths[0]+\"_aligned_rt.npy\"\n",
    "        opt.tgt_ani_path = paths[0]+\"_aligned_ani.mp4\"\n",
    "\n",
    "        # reference\n",
    "        ref_paths = paths\n",
    "        opt.ref_ani_id = int(paths[-1])\n",
    "        opt.ref_front_path = ref_paths[0]+\"_aligned_front.npy\"\n",
    "        opt.ref_video_path = opt.tgt_video_path\n",
    "        opt.ref_lmarks_path = paths[0]+\"_aligned.npy\"\n",
    "        opt.ref_rt_path = opt.tgt_rt_path\n",
    "        if opt.no_head_motion:\n",
    "            opt.ref_img_id = str(opt.ref_ani_id)\n",
    "            opt.n_shot = 1\n",
    "\n",
    "        audio_tgt_path = paths[0]+\".wav\"\n",
    "\n",
    "    return audio_tgt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65b53dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = TestOptions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b4ae826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<options.test_options.TestOptions at 0x7fd11ba7d668>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d5bcdec",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TestOptions' object has no attribute 'gpu_ids'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-a3bc1c1a6aab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### setup models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/Emotech/Talking-head-Generation-with-Rhythmic-Head-Motion/models/models.py\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(opt, epoch)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVid2VidModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model [%s] was created\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/Emotech/Talking-head-Generation-with-Rhythmic-Head-Motion/models/vid2vid_model.py\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(self, opt, epoch)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mBaseModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/Emotech/Talking-head-Generation-with-Rhythmic-Head-Motion/models/base_model.py\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(self, opt)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misTrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misTrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_ids\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TestOptions' object has no attribute 'gpu_ids'"
     ]
    }
   ],
   "source": [
    "### setup models\n",
    "model = create_model(opt)\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
